# -*- coding: utf-8 -*-
"""ML_Assign3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/173YgtwWWXv790mXqWwza6zkqtLtA1mY2
"""

#QUESTION 1
import pandas as pd

df = pd.read_csv('AWCustomersAssign2.csv')

df.head()

columns_to_drop = ['CustomerID', 'Title', 'FirstName', 'MiddleName', 'LastName', 'Suffix', 'AddressLine1', 'AddressLine2', 'LastUpdated', 'StateProvinceName',
                   'CountryRegionName', 'PhoneNumber']

df_cleaned = df.drop(columns=columns_to_drop)
df_cleaned.head()

data_types = {
    'City': {'Type': 'Discrete', 'Scale': 'Nominal'},
    'PostalCode': {'Type': 'Discrete', 'Scale': 'Nominal'},
    'BirthDate': {'Type': 'Continuous', 'Scale': 'Interval'},  # Can be used to calculate Age
    'Education': {'Type': 'Discrete', 'Scale': 'Ordinal'},
    'Occupation': {'Type': 'Discrete', 'Scale': 'Nominal'},
    'Gender': {'Type': 'Discrete', 'Scale': 'Nominal'},
    'MaritalStatus': {'Type': 'Discrete', 'Scale': 'Nominal'},
    'HomeOwnerFlag': {'Type': 'Discrete', 'Scale': 'Nominal'},
    'NumberCarsOwned': {'Type': 'Discrete', 'Scale': 'Ratio'},
    'NumberChildrenAtHome': {'Type': 'Discrete', 'Scale': 'Ratio'},
    'TotalChildren': {'Type': 'Discrete', 'Scale': 'Ratio'},
    'YearlyIncome': {'Type': 'Continuous', 'Scale': 'Ratio'}
}

data_type_df = pd.DataFrame(data_types).T
data_type_df

#QUESTION 2 Part i
import pandas as pd
from sklearn.impute import SimpleImputer

df = pd.read_csv('AWCustomersAssign2.csv')
columns_to_drop = ['CustomerID', 'Title', 'FirstName', 'MiddleName', 'LastName', 'Suffix', 'AddressLine1', 'AddressLine2', 'LastUpdated', 'StateProvinceName',
                   'CountryRegionName', 'PhoneNumber']

df_cleaned = df.drop(columns=columns_to_drop)

#Displays the number of null values
null_values = df_cleaned.isnull().sum()
print(null_values)

#Use mode for Categorical Columns
categorical_columns = df_cleaned.select_dtypes(include=['object']).columns
imputer = SimpleImputer(strategy='most_frequent')
df_cleaned[categorical_columns] = imputer.fit_transform(df_cleaned[categorical_columns])

#Use mean for Numerical Columns
numerical_columns = df_cleaned.select_dtypes(include=['number']).columns
imputer = SimpleImputer(strategy='mean')
df_cleaned[numerical_columns] = imputer.fit_transform(df_cleaned[numerical_columns])

null_values_after = df_cleaned.isnull().sum()
print(null_values_after)

#QUESTION 2 Part ii and Part iv
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler


df = pd.read_csv('AWCustomersAssign2.csv')
columns_to_drop = ['CustomerID', 'Title', 'FirstName', 'MiddleName', 'LastName', 'Suffix', 'AddressLine1', 'AddressLine2', 'LastUpdated', 'StateProvinceName',
                   'CountryRegionName', 'PhoneNumber']

df_cleaned = df.drop(columns=columns_to_drop)

#MinMax Scaler
scaler = MinMaxScaler()
numerical_columns = df_cleaned.select_dtypes(include=['number']).columns
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

#Standard Scaler also in Standardization
scaler = StandardScaler()
numerical_columns = df_cleaned.select_dtypes(include=['number']).columns
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

#Similarly for Robust Scaler and MaxAbs Scaler

#QUESTION 2 Part iii
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv('AWCustomersAssign2.csv')
columns_to_drop = ['CustomerID', 'Title', 'FirstName', 'MiddleName', 'LastName', 'Suffix', 'AddressLine1', 'AddressLine2', 'LastUpdated', 'StateProvinceName',
                   'CountryRegionName', 'PhoneNumber']

df_cleaned = df.drop(columns=columns_to_drop)

#Discretization (Binning) for 'YearlyIncome' using pd.cut
bins = np.linspace(df_cleaned['YearlyIncome'].min(), df_cleaned['YearlyIncome'].max(), 4)  # 4 bins
group_names = ['Low Income', 'Middle Income', 'High Income']  # Labels for the bins

# Apply the binning to 'YearlyIncome'
df_cleaned['IncomeCategory'] = pd.cut(df_cleaned['YearlyIncome'], bins=bins, labels=group_names, include_lowest=True)

# Display the first few rows of the DataFrame with the new 'IncomeCategory' column
print(df_cleaned.head())

#QUESTION 2 Part v

import pandas as pd
from sklearn.preprocessing import OneHotEncoder

df = pd.read_csv('AWCustomersAssign2.csv')

#columns we want to One-Hot Encode
columns_to_encode = ['Sex', 'Embarked']

# Initialize the OneHotEncoder
onehotencoder = OneHotEncoder(sparse=False, drop='first')  # drop='first' avoids multicollinearity by dropping one category

# Fit and transform the data
encoded_data = onehotencoder.fit_transform(df[columns_to_encode])

# Convert the encoded data to a DataFrame with appropriate column names
encoded_df = pd.DataFrame(encoded_data, columns=onehotencoder.get_feature_names_out(columns_to_encode))

# Concatenate the encoded columns with the original DataFrame (dropping the original columns)
df_encoded = pd.concat([df.drop(columns_to_encode, axis=1), encoded_df], axis=1)

# Display the first few rows to check the result
print(df_encoded.head())

for char in "Python":
  print(char)